{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html, etree\n",
    "from io import StringIO\n",
    "import re\n",
    "\n",
    "# from .WordMonthExtractor import WordMonthExtractor\n",
    "# from .HalfYearExtractor import HalfYearExtractor\n",
    "# from .FromToExtractor import FromToExtractor\n",
    "# from .ReleaseDateExtractor import get_release_date\n",
    "\n",
    "class HocrParser:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.doc = None\n",
    "        self.root = None\n",
    "        self.parsed_document = None\n",
    "\n",
    "\n",
    "    def read_file(self, path):\n",
    "        with open(path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            lines = file.readlines()\n",
    "            first_line_i = 0\n",
    "            for i, line in enumerate(lines):\n",
    "                if line.find(\"xml version\") > -1:\n",
    "                    first_line_i = i\n",
    "                    break\n",
    "            xml_string = \"\".join(lines[first_line_i + 1:])\n",
    "            parser = etree.HTMLParser()\n",
    "            self.doc = etree.parse(StringIO(xml_string), parser)\n",
    "            self.root = self.doc.getroot()\n",
    "            del lines\n",
    "\n",
    "\n",
    "    def parse_(self):\n",
    "        document = []\n",
    "        pages = [page for page in next(x for x in self.root if x.tag == 'body') if page.attrib.get('class', \"\") == 'ocr_page']\n",
    "        for page in pages:\n",
    "            page_l = []\n",
    "            lines = [line for line in page if line.attrib.get('class', \"\") == 'ocrx_line']\n",
    "            for _, line in enumerate(lines):\n",
    "                words = [word.text for word in line if\n",
    "                         word.attrib.get('class', \"\") == 'ocrx_word' and type(word.text) == str]\n",
    "                if words:\n",
    "                    line_joined = \" \".join(words)\n",
    "                page_l.append(line_joined)\n",
    "            document.append(page_l)\n",
    "        self.parsed_document = document\n",
    "        return document\n",
    "\n",
    "#     def get_company(self):\n",
    "#         print(\"dupa\")\n",
    "\n",
    "    def get_company(self):\n",
    "        company=''\n",
    "        flag=0\n",
    "        r = re.compile('spół*|kapita*|finanso*')\n",
    "        forma=['s.a.','spółka akcyjna']\n",
    "        text=[j for i in self.parsed_document for j in i]\n",
    "        for x in text:\n",
    "            #print(x.lower())\n",
    "            for i in x.lower().split():\n",
    "                 if i in forma and flag==0:\n",
    "                        company=(x.split()[:x.lower().split().index(i)])\n",
    "                        flag=1\n",
    "        company=\" \".join(company)\n",
    "        syf_idx = [i for i, item in enumerate(company.lower().split()) if re.search(r'spół*|kapita*|finanso*|the|(\\w+:)|^of$|działalności|pół*|zgromadzenia|(\\w+czny)|zarządu|^do$|^o$|grupa|roku|dominują*', item)]\n",
    "        if len(syf_idx)>0:\n",
    "            return \" \".join(company.split()[syf_idx[len(syf_idx)-1]+1:])\n",
    "        else:\n",
    "            return \" \".join(company.split())\n",
    "        \n",
    "    def get_release_date(self):\n",
    "        return get_release_date(self.parsed_document)\n",
    "\n",
    "#     def get_dates(self):\n",
    "#         text = \" \".join(self.parsed_document[0][0:15])\n",
    "#         text = text.lower()\n",
    "        \n",
    "#         extractors = [\n",
    "#             HalfYearExtractor(), \n",
    "#             WordMonthExtractor(), \n",
    "#             FromToExtractor()\n",
    "#             ]\n",
    "\n",
    "#         for extractor in extractors:\n",
    "#             dates = extractor.extract(text)\n",
    "#             if dates is not None:\n",
    "#                 return dates[0].isoformat(), dates[1].isoformat()\n",
    "        \n",
    "#         return None\n",
    "\n",
    "####### Example usage: #######\n",
    "# parser = HocrParser()\n",
    "# parser.read_file(\"./data/contest/train/reports/208910/ZMR_PSr_2012_SPRAWOZDANIE_ZARZADU.hocr\")\n",
    "# parser.read_file(\"./data/contest/train/reports/15988/rozszerzone_skonsolidowane_sprawozdanie__finansowe_Grupy_Kapitalowej_ProchemSA_na_30.06.2005.hocr\")\n",
    "# document = parser.parse_()\n",
    "# release_date = parser.get_release_date()\n",
    "# dates = parser.get_dates()\n",
    "#company_names=parser.get_company()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company(document):\n",
    "    company=''\n",
    "    flag=0\n",
    "    r = re.compile('spół*|kapita*|finanso*')\n",
    "    forma=['s.a.','spółka akcyjna']\n",
    "    text=[j for i in document for j in i]\n",
    "    for x in text:\n",
    "        for i in x.lower().split():\n",
    "             if i in forma and flag==0:\n",
    "                    company=(x.split()[:x.lower().split().index(i)])\n",
    "                    flag=1\n",
    "    company=\" \".join(company)\n",
    "    syf_idx = [i for i, item in enumerate(company.lower().split()) if re.search(r'spół*|kapita*|finanso*|the|(\\w+:)|^of$|działalności|pół*|zgromadzenia|(\\w+czny)|zarządu|^do$|^o$|grupa|roku|dominują*', item)]\n",
    "    if len(syf_idx)>0:\n",
    "        return \" \".join(company.split()[syf_idx[len(syf_idx)-1]+1:])\n",
    "    else:\n",
    "        return \" \".join(company.split())\n",
    "    #print(company.split()[3])\n",
    "    #zmianami, Zarząd Spółki Dominującej - Chemoservis-Dwory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "company_names=[]\n",
    "dir_names=[]\n",
    "rootdir = r'C:\\PW\\NLP\\contest\\train'\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    #filename = os.fsdecode(files)\n",
    "    for file in files:\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".hocr\"):\n",
    "            filepath=os.path.join(subdir, file)\n",
    "            dir_names.append(os.path.basename(subdir))\n",
    "            #print(filepath)\n",
    "            parser = HocrParser()\n",
    "            parser.read_file(filepath)\n",
    "            doc=parser.parse_()\n",
    "            #get_company(doc)\n",
    "            company_names.append(parser.get_company())\n",
    "            #company_names.append(get_company(doc))\n",
    "            #print(company_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.DataFrame(list(zip(dir_names, company_names)))\n",
    "#df.to_csv('output.csv', sep=';', encoding='utf-8',index=False)\n",
    "\n",
    "\n",
    "truth=pd.read_csv('ground_truth-train.csv', sep=';')\n",
    "truth=truth.iloc[:,0:2]\n",
    "df.columns = ['id', 'company_pred']\n",
    "\n",
    "df[\"id\"] = pd.to_numeric(df[\"id\"])\n",
    "df[\"company_pred\"] = df[\"company_pred\"].astype('str') \n",
    "#truth.set_index('id').join(df.set_index('id'))\n",
    "merged=df.join(truth.set_index('id'), on='id')\n",
    "merged[['company']]\n",
    "#merged['company']= merged['company'].map(lambda x: x.rstrip(' SA$ | S.A.$' | S.A$))\n",
    "merged['company'] = merged['company'].astype(str)\n",
    "merged['company_pred'] = merged['company_pred'].astype(str)\n",
    "merged['company'].replace(regex=True,inplace=True,to_replace=r' SA| S.A.| Spółka Akcyjna| SPÓŁKA AKCYJNA| SPÓLKA AKCYJNA',value=r'')#.str.upper() #|Spółka Akcyjna|SPÓŁKA AKCYJNA$\n",
    "merged['company_pred'] = merged['company_pred'].str.upper()\n",
    "merged['company'] = merged['company'].str.upper()\n",
    "merged['company'] = merged['company'].replace(' - ', '-')\n",
    "merged['company'] = merged['company'].replace('\"', '')\n",
    "merged['company_pred'] = merged['company_pred'].replace('\"', '')\n",
    "\n",
    "#df.iloc[:, i] = df.iloc[:, i].str.replace('\"', '')\n",
    "merged.to_csv('compare.csv', sep=';', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HocrParser()\n",
    "#parser.read_file(\"./data/contest/train/reports/208910/ZMR_PSr_2012_SPRAWOZDANIE_ZARZADU.hocr\")\n",
    "parser.read_file(r'C:\\PW\\NLP\\contest\\train\\reports\\367072\\Abadon_Real_Estate_S.A._skonsolidowany_raport_-_I_polrocze_2017.hocr')\n",
    "\n",
    "document = parser.parse_()\n",
    "#release_date = parser.get_release_date()\n",
    "#423396;WYBRANE DANE FINANSOWE INTROL;INTROL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABADON REAL ESTATE'"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_company(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "KREDYT INKASO\n"
     ]
    }
   ],
   "source": [
    "# śmieciiiii\n",
    "\n",
    "\n",
    "#document[0][3].split()[2]=='S.A.'\n",
    "#document[1][1].split()\n",
    "document[0][3]\n",
    "\n",
    "#abc=re.search(\"S.A.\", document[0][3])\n",
    "#print(abc)\n",
    "\n",
    "forma=['s.a.','spółka akcyjna','(„emitent”)']\n",
    "text=[j for i in document for j in i]\n",
    "\n",
    "company=''\n",
    "flag=0\n",
    "for x in text:\n",
    "    #print(x.lower())\n",
    "    for i in x.lower().split():\n",
    "         if i in forma and flag==0:\n",
    "                company=(x.split()[:x.lower().split().index(i)])\n",
    "                flag=1\n",
    "company=\" \".join(company)\n",
    "r = re.compile('spół*|kapita*|finanso*')\n",
    "#newlist = list(filter(r.match, company.lower().split()))\n",
    "\n",
    "syf_idx = [i for i, item in enumerate(company.lower().split()) if re.search(r'spół*|kapita*|finanso*|\\b(\\w+czny)\\b', item)]\n",
    "\n",
    "print(syf_idx)\n",
    "if len(syf_idx)>0:\n",
    "    print(\" \".join(company.split()[syf_idx[len(syf_idx)-1]+1:]))\n",
    "else:\n",
    "    \" \".join(company.split())\n",
    "#Jednostką Dominującą w Grupie Kapitałowej Work Service jest spółka Work Service"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dupa",
   "language": "python",
   "name": "shogunenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
